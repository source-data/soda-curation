#################
#################
# config/config.yaml
default: &default
  # Provider-specific base configurations
  providers:
    openai: &openai_base
        model: gpt-4o
        temperature: 0.1
        top_p: 1.0
        max_tokens: 2048
        frequency_penalty: 0.0
        presence_penalty: 0.0
        json_mode: true

  # Pipeline step configurations
  pipeline:
    extract_sections:
      openai:
        <<: *openai_base
        model: gpt-4
        prompts:
          system: |
            Your prompt goes here
            In a multi line fassion
          user: | 
            The user prompt goes here

    extract_individual_captions:
      openai:
        <<: *openai_base
        model: gpt-4
        prompts:
          system: |
            Your prompt goes here
            In a multi line fassion
          user: | 
            The user prompt goes here

    extract_data_sources:
      openai:
        <<: *openai_base
        model: gpt-4
        prompts:
          system: |
            Your prompt goes here
            In a multi line fassion
          user: | 
            The user prompt goes here

    assign_panel_source:
      openai:
        <<: *openai_base
        model: gpt-4
        prompts:
          system: |
            Your prompt goes here
            In a multi line fassion
          user: | 
            The user prompt goes here

    match_caption_panel:
      openai:
        <<: *openai_base
        model: gpt-4
        prompts:
          system: |
            Your prompt goes here
            In a multi line fassion
          user: | 
            The user prompt goes here

    object_detection:
      model_path: "data/models/panel_detection_model_no_labels.pt"
      confidence_threshold: 0.25
      iou_threshold: 0.1
      image_size: 512
      max_detections: 30

